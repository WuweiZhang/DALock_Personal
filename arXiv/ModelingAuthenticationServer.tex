% !TEX root = main.tex
\subsection{Modeling the Authentication Server}\label{section:ExperimentDesign-subsection:SimulateServer} %Done
We model an authentication server running $\DALock$ with various parameters $\strikeThreshold$ and $\hitCountThreshold$ for the strike count and hit count. Each time a user $u$ (or attacker pretending to be $u$) attempts to login the authentication server updates the parameters $\hitCountThresholdOfU{u}$ and $\strikeThresholdOfU{u}$ accordingly following the $\DALock$ mechanism. We remark that when $ \hitCountThreshold = \infty$ that the authentication server is running the classical $ \strikeThreshold$-strikes lockout policy. To deploy $\DALock$ with a finite hit-count parameter $ \hitCountThreshold$ an authentication server needs to use a frequency oracle to update the hit count after each incorrect login attempt.  In this work we consider two concrete approaches the authentication server might adopt: (differentially private) Count Sketch estimator and Password Strength Models. We use $\EstimateP{pw}{\Estimator}$ to denote the estimated popularity (probability) of a password $pw$ using the estimator $\Estimator$ e.g., given a Count-Sketch $\sigma$ we would use  $\EstimateP{pw}{\sigma} = \frac{\mathbf{Estimate}(pw,\sigma)}{\mathbf{TotalFreq(\sigma)}}$. We remark that the authentication server might (optionally) chose to ban overly popular passwords to flatten the password distribution to protect user accounts against online attackers \cite{HTS:SchHerMit10}. If the authentication server adopts such policy, then the frequency oracle would need to be adjusted accordingly to model the new password distribution.


\subsubsection{Differentially Private Count Sketch Estimator} 
The first instantiation of $\EstimateP{\cdot}{\cdot} $ we consider is to build a Count Sketch Estimator $\sigma_{\SampledData{\AllUser}} = \Add{\SampledData{\AllUser}}{\sigma} $ from our dataset $\SampledData{\AllUser} $ of user passwords. To build a Count Sketch in practice the authentication server would update the Count Sketch with the new password each time a user registers \footnote{The Count Sketch instantiations we consider would also support a Remove operation which would allow the authentication server to handle password updates efficiently}. There are several issues to consider when deploying the Count Sketch estimator: memory efficiency, privacy, sample size and accuracy. 

\textbf{Memory Efficiency} We instantiate the Count Sketch with parameters $d=5$ and $w=10^6$ so that the entire data structure requires just $20$ MB of space which easily fits in RAM. 

\textbf{Privacy} As we discussed earlier one concern about storing a Count Sketch $\sigma_{\SampledData{\AllUser}} $ on the authentication server is that an offline attacker might steal this file and use the data-structure to help identify user passwords. For example, if our user John Smith selects (resp. does not select) the password ``J.S.UsesStr0ngpwd!'' then we would expect that the true frequency of this password is $\TrueFInD{pw}{\SampledData{\AllUser} }=1$ (resp. $\TrueFInD{pw}{\SampledData{\AllUser} }=0$). If the Count Sketch estimator is overly accurate then the attacker would be able to learn that one user (most likely John Smith) picked this password. Without a way to address these privacy concerns an organization might be understandably wary to deploy a Count Sketch estimator.

To address these privacy concerns we consider an $\epsilon$- differentially private estimator $\sigma_{dp}$ = \textbf{DP($\epsilon,\sigma$)} in our experiments. During initialization we add Laplace noise to each of the cells in the Count Sketch where the noise parameter scales with $d/\epsilon$. In our above example, differential privacy ensures that --- up to a multiplicative advantage $e^{\epsilon}$ --- an attacker cannot use the count sketch to distinguish between a dataset in which John Smith did (resp. did not) pick the password ``J.S.UsesStr0ngpwd!' We remark that lower values of $\epsilon$ correspond to stronger privacy guarantees e.g., we use $\epsilon=\infty$ to denote the case with no differential privacy guarantees. In most of our experiments we use a small privacy parameter $\epsilon=0.1$ which is much smaller than the privacy parameters used in most prior deployments of differential privacy e.g.,  \cite{NDSS:BloDatBon16,AppleDPTeam,CCS:ErlPihKor14}. 

\textbf{Sample Size and Accuracy} In general the accuracy of a Count Sketch increases with the size of the password dataset. Suppose that the organization does not have millions of users or the that the sample size is decreased because the organization allows users to ``opt-in'' to the (differentially private) count sketch. One natural question is whether a smaller organization would be able to deploy a Count Sketch to obtain reliable frequency estimates. We investigate this question by subsampling smaller datasets to train the Count Sketch. Given a set $\AllUser$ of $N$ users we use $\AllUser_{r\%}$ to denote a randomly subsampled set of $r\%$ of users. We use $\SampledData{\AllUser_{r\%}}$ to denote the corresponding subsampled password dataset $\sigma_{r\%} = \Add{\SampledData{\AllUser}}{\sigma} $ to denote the Count Sketch trained on the subsampled data. The question is whether $\sigma_{r\%}$ can be as effective as $\sigma$ for deploying $\DALock$. 

In our experiments we consider the following sampling rates: 1\%, 5\%, and 10\%. We find that even when $r=1\%$ the Count Sketch $\CountSketch$ trained on $\SampledData{\AllUser_{1\%}}$ is sufficiently accurate --- even if we additionally add Laplace noise to preserve $\epsilon=0.1$-differential privacy. 

%Let $\sigma_{r\%}$ be the Count Sketch trained based on $\AllUser_{r\%}$, r\% of the users,  who choose to participate. The question is whether $\sigma_{r\%}$ can be as effective as $\sigma$ for deploying $\DALock$. To investigate it's deployability, we include $\sigma_{r\%}$ constructed by $\AllUser_{r\%}$ as part of our experiments. 

%Count Sketch Estimator $\sigma$ is the first approach for implementing frequency oracle. A standard Count Sketch $\sigma$ trained based on input dataset $\SampledData{\AllUser}$ (as described in \textbf{Section}~\ref{section:Prelinmaries-CountSketch}) can be memory-efficient and accurate. However, $\sigma$ may not be obtainable or usable due to various reasons in real life scenarios (e.g. information protection law). Therefore, we also consider the following types of $\CountSketch$ estimators.

%\textbf{Differential Private Count Sketch}
%Privacy leakage risks exist if one directly deploys $\DALock$ with standard $\sigma$. One sounding solution is to adopt differential privacy to reduce the surface of vulnerabilities; however, it's questionable whether Count-Sketch based $\DALock$ can still be effective when privacy budget is limited. e.g. $\epsilon = 0.1$. To assess its effectiveness under such situation, we also include differential private Count-Sketch estimator $\sigma_{dp}$ = \textbf{DP($\epsilon,\sigma$)} in the experiments. In particular, we are interested in low privacy budget scenarios so data curators can periodically update $\sigma_{dp}$ without significant cumulative privacy loss.



%\textbf{Building Count Sketch with Low Participation Ratio}
%There are multiple incentives to train a Count Sketch on a small dataset. For instance, new business may not have an enormous number of users at beginning. For mature ones, one challenge data curator may face is low participation in password statistics sharing. Human generated passwords can contain sensitive information such data of birth, therefore it's possible that not everyone is willing to opt-in. 



\textbf{Count Sketch with Banlists} In our simulations we also consider an authentication server that bans the most popular $B=10^4$ passwords in a dataset to help flatten the password distribution and protect users against online attacks. Theoretical analysis indicates that directly banning the most popular passwords is the most effective way to increase the minimum entropy of the password distribution~\cite{BKPS:ACMEC13}. We remark that one additional benefit of using a Count Sketch data structure is that it can be used to help implement this type of policy i.e., if a user attempts to register with password $pw$ and $\EstimateP{pw}{\sigma}$ is already too high then the user will be required to pick a different password~\cite{HTS:SchHerMit10}.

We evaluate the performance of $\DALock$ in the presence of banlists. Recall that we let $\SampledData{\AllUser, B}$ denote the dataset $\SampledData{\AllUser}$ with the $B$ most common passwords removed following the normalized probabilities model of ~\cite{BKPS:ACMEC13} to model how affected users will update their passwords in response to the banlist. In particular, we assume users who are affected by the policy will pick a new passwords following the empirical distribution induced by $\SampledData{\AllUser, B}$. We then train the Count Sketch on the updated dataset i.e., $\sigma_{-B} = \text{Add}(\SampledData{\AllUser, B})$ as follows. 

% The core idea behind $\DALock$ is punishing attempts with over popular passwords. One natural following question is what happens if the distribution is not so skewed? One way to achieve such distribution is via banning over popular credential\cite{HTS:SchHerMit10}. Recent studies show\cite{BKPS:ACMEC13,HTS:SchHerMit10} that password composition policies can flaten distributions and discourage attackers. $\DALock$ punishes attempts on over popular credentials while there is no such password under this circumstance. It is worthwhile to test if $\DALock$ can still outperform traditional throttling mechanism. To conduct this type of experiment we implement $\DALock$ with Count Sketch $\sigma_{-b} = \text{Add}(\SampledData{-b})$ as follows. Let b the number of banned passwords, we first construct $\SampledData{-b}$ via banning top b passwords in $\SampledData{\AllUser}$. We assume users who are affected by the policy will pick a new password based on the distribution of remaining passwords in this process. After that, we construct $\sigma_{-b}$ based on the obtained dataset $\SampledData{-b}$


\subsubsection{Frequency Oracle from Password Models}
As we previously discussed there are several reasons why an organization might prefer not to use a Count Sketch for frequency estimation e.g., privacy concerns or limited sample size. An alternative is to instantiate the frequency oracle with a password model. This could be a heuristic password strength meter, a more sophisticated model based on Neural Networks, Probabilistic Context Free Grammars or Markov Models or an empirical estimate based on Hashcat. The primary advantage to this approach is that the model can be deployed immediately even before an organization has any users and there are no privacy concerns. 

We adopted the $\ZXCVBN$ password strength meter~\cite{USENIX:Wheeler16} as prior empirical studies  demonstrate that it is one of the most accurate password strength meters \cite{CCS:GolDur18}. We used the Password Guessing Service \cite{USENIX:USBCCKKMMS15} to obtain guessing numbers for Neural Network, PCFG, Hashcat, and Markov Models ---  we also considered the  minimum guessing number across all four models as suggested in \cite{USENIX:USBCCKKMMS15}. For example, if a password $pw$ had guessing number $g$ we might estimate that $\EstP{pw_i} =1/g$. One challenge that we needed to address was that the estimates we obtain do not always yield a probability distribution e.g., for $\ZXCVBN$ we have $\sum_{i=1}^{10000}\EstP{pw_i} \gg 1$ where $i$ ranges over the top $10^4$ passwords in the dataset. Thus, before deploying the frequency estimator in $\DALock$ we renormalized our estimates so that $\sum_{i=1}^{10000}\EstP{pw_i} =1$. 

% In this work we also seek alternatives to $\CountSketch$ which does not require collecting users' passwords from the server. Literature\cite{CCS:GolDur18} shows that some of them can adequately compute the strength of weak credentials. Therefore, we implement $\DALock$ with the following frequency oracles and tested their performance: $\ZXCVBN$\cite{USENIX:Wheeler16}, Neural Network, PCFG, Hashcat, and Markov Model ( the later four are based on estimation of PGS\cite{USENIX:USBCCKKMMS15}). 
% Implementing frequency oracle by this approach can be a challenging task as they output (strength) scores for passwords in lieu of popularities. To overcome the issue, we define the popularites of password $pw$ to be its estimated score over the total score of top 20,000 passwords. i.e $\EstP{pw} = \frac{\EstP{pw}}{\sum_{i=1}^{20000}\EstP{pw_i}}$.
