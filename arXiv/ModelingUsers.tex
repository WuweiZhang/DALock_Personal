% Comment Unwanted text for later S&p Submission
% !TEX root = main.tex
\subsection{Modeling Users} \label{section:ExperimentDesign-subsection:SimulateUser}
Our model to simulate the behavior of honest users consists of three key components: user password selection, login frequency, and mistake model. %Our approach can be briefly described as follows. Firstly, we simulate user's choice of password based on three empirical password datasets (See \textbf{Section}~\ref{section:ExperimentDesign-subsection:SimulateUser-subsubsection:SimulatePasswordChoice} for more details). Secondly, following prior works \cite{AC:BloBluDat13}\cite{CCS:KogManBon17} we adopt Poisson arrival process to simulate to model user's login habitats and patterns (\textbf{Section}~\ref{section:ExperimentDesign-subsection:SimulateUser-subsubsection:SimulateLoginPattern}). Finally, following prior works on password typos\cite{CCS:CWPCR17}, we model user's honest mistakes by augment the exisiting model with a method to simulate mistakes other than typos. 





\subsubsection{Simulating Users' Choice of Password}\label{section:ExperimentDesign-subsection:SimulateUser-subsubsection:SimulatePasswordChoice}
In each simulation we fix a dataset which is used to simulate user password selection. We use three large empirical password datasets: RockYou, LinkedIn and Yahoo! In particular, a dataset consists of a multiset  $\SampledData{\AllUser} = {pw_1,...,pw_N}$ of $N$ user passwords which can be compressed into pairs $(pw,  \TrueFInD{pw}{\SampledData{\AllUser} })$ --- recall that $\TrueFInD{pw}{\SampledData{\AllUser} }$ denotes the number of time the password $pw$ occurs in the dataset $\SampledData{\AllUser}$.   See  \textbf{Section}~\ref{section:ExperimentDesign-subsection:SimulateUser-subsubsection:SimulatePasswordChoice} for a more details about each dataset. Each of these datasets $\SampledData{\AllUser} $ induces an empirical distribution over user passwords where the probability of sampling each password $pw$ is simply $\TrueFInD{pw}{\SampledData{\AllUser}}/N$\footnote{In our analysis we will assume that the empirical distribution is the {\em real distribution} over user passwords and which is also known to the attacker. Given a password dataset $\SampledData{\AllUser} $ sampled from the real distribution over user passwords we remark that when analyzing online attacks we focus on popular passwords where empirical distribution and the real distribution will be very similar. }.  Each simulated user $u$ in our experiment samples $6$ passwords from this empirical distribution and registers with the first password. Intuitively, the five extra sampled passwords will be used to help simulate recall errors e.g., they represent the user's passwords for other websites. 

We remark that the Yahoo! dataset~\cite{SP:Bonneau12,NDSS:BloDatBon16} only contains frequencies without actual passwords i.e., instead of recording the pair $(pw,  \TrueFInD{pw}{\SampledData{\AllUser} })$ the dataset simply records $\TrueFInD{pw}{\SampledData{\AllUser} }$ . We generate a complete password dataset by designating a unique string for each password. As we avoid using password models like $\ZX$ to analyze $\DALock$ with the Yahoo! dataset since frequency estimation requires access to the original passwords. However, we are still able to evaluate $\DALock$ with the Yahoo! dataset using the Count-Sketch frequency oracle. 

\mypara{Banlists} We additionally consider the setting where the authentication server chooses to ban users from selecting the top $B$ passwords e.g., $B=10^4$ passwords. We use the normalized probabilities model~\cite{BKPS:ACMEC13} to simulate user password selection under such restrictions. In this model we simply use rejection sampling to avoid sampling one of the top $B$ passwords. Equivalently, we can let $\SampledData{\AllUser, B}$ denote the dataset $\SampledData{\AllUser}$ with the $B$ most common passwords removed and sample from the empirical distribution corresponding to the updated dataset $\SampledData{\AllUser, B}$.

%In particular, if a password $pw$ is one of the top $10^5$ passwords the probability that user $u$ samples $pw$ is updated to be $0$. The probabilities of all remaining passwords are renormalized conditioning on the event that we don't sample one of the top $10^5$ passwords. An alternative view is that we can simply remove the top $10^5$ passwords from our dataset and sample from the new empirical distribution.

%In this part we discuss how we simulate usersâ€™ passwords. Our model assumes that $u$ has 6 passwords in their mind where 5 of them are ``passwords for other websites". The extra passwords are primarily used to simulate recall error which is discussed later.(\textbf{Section}~\ref{section:ExperimentDesign-subsection:SimulateUser-subsubsection:SimulateUserMistake}). For the rest of the discussion, we abusively refer ``actual distribution" to be the empirical datasets listed in \textbf{Section}~\ref{section:experiment:experiment_dataset}. Despite that there could be misalignment with the underlying distribution, we believe those datasets are sufficient large and the impacts of misalignment are almost negligible.


%\mypara{Simulating Password Choice on LinkedIn and RockYou} Given both the plaintext passwords and the distribution statistics, we simulate user's choice of password $pw_u$ by simplying sample a password from the actual distribution. i.e. the probability choosing $pw$ is identical to it's actual popularity density, $\TrueP{pw}$, in the dataset. For example, to simulate user $u$'s password on RockYou, u has probability 0.89\% of picking ``123456" as their password.

%\wuwei{This paragraph needs polishing}
%\mypara{Simulating Password Choices on Yahoo!} Simulating user's choice of password on Yahoo dataset involves an extra step: generate plaintext password string because it only contains the statistics of passwords. Notice that based on \textbf{Table}~\ref{table: datasetsummary},
%Yahoo contains more unique passwords than the rest two therefore it's impossible to fully map the dataset. To conquer this issue, we map password strings from RockYou to Yahoo as follows. Firstly, we sample users' choice of passwords from Yahoo based on its current distribution. Secondly, we map the top 20,000 passwords from RockYou to the top 20,000 passwords of Yahoo. For example, $pw_1$ and $pw_2$ from Yahoo are represented by ``123456" and ``12345" respectively, top 2 passwords from RockYou.The goal of this step is to ensure an adequate string representation of popular passwords. Literatures\cite{EPRINT:WJHW14,TIFS17:WCWPXG,ESORICS:WanWan16,SP:BloHarZho18} suggests that Yahoo and RockYou both follows Zipf's law, thus there is are huge gaps among top ranks. Thirdly, we map the rest of (RockYou) passwords to Yahoo according to their rankings and the users' choice.  For selected passwords, we map them from passwords with similar ranks in RockYou. On the other hand, we map the unselected passwords uniformly, roughly every 4, from RockYou. 


\subsubsection{Simulating user's login patterns}\label{section:ExperimentDesign-subsection:SimulateUser-subsubsection:SimulateLoginPattern} %Done
To simulate each user we need to model the frequency with which our honest user attempts to login to the authentication server. In particular, we aim to simulate the login behavior over a 180-day time span. For each user $u$ we want to generate a sequence $0 < t_1^u < t_2^u < \cdots <  4320 = 180\times24$  where each $t_i^u \in \mathbb{N}$ represents the time (hour) of the $i$th user visit. Following prior work (e.g., see \cite{AC:BloBluDat13,CCS:KogManBon17}) we use a Poisson arrival process to generate these login times. The Poissuon arrival process is parameterized by an arrival rate $T_u$ (hours) which encodes the expected time between consecutive login attempts $T_u = \mathbb{E}[t_{i+1}-t_i]$, and the arrival process is memoryless so the actual gap $t_{i+1}-t_i$  is independent of $t_i$. Since some users are more active than others we pick a different arrival rate $T_u$ for each user $u$ where each $T_u$ is sampled uniformly random from $\{ 12, 24, 24 \times 3, 24 \times 7, 24 \times 14, 24 \times 30\}$. The parameter $T_u = 12$ (hours) corresponds to users who visit multiple times per day on average, while the parameter $T_u = 24 \times 30$ corresponds to a user who visits the site once per month. For each user $u$ we use the Poisson arrival process with parameter $T_u$ to generate the sequence of visits $0 < t_1^u < t_2^u < \cdots <  4320 = 180\times24$   over a time span of $180$ days ($4320$ hours). Each time a user visits we assume that they will continue attempting to login until they succeed or get locked out. %We don't simulate users who completely forget their passwords as these users will need to reset their passwords independently of the deployed throttling mechanism. 

We remark that we do not simulate a client device which automatically attempts to login on the user's behalf. It may be desirable to have the authentication server store the (salted) hash of the user's previous password(s) so that we can avoid locking the user's account in settings where a client device might repeatedly attempt to login with an outdated password. Alternatively, the authentication server could store an encrypted cache of incorrect login attempts using public key cryptography where each incorrect login attempt $pw_u' \neq pw_u$ would be encrypted with a public key $pk_u$ and stored on the authentication server. The encrypted cache could only be decrypted when the user authenticates with the correct password\footnote{Unlike the public encryption key $pk_u$, which would be stored on the authentication server, the secret key $sk_u$ would only be stored in encrypted form i.e., the server would store $c_u = \mathbf{Enc}_{K_u}(sk_u)$ where $K_u = \mathbf{KDF}(pw_u)$ is a symmetric encryption key derived from the user's password. }. The encrypted cache could be used as part of a personalized typo corrector~\cite{CCS:CWPCR17} and could also be used to avoid penalizing repeat mistakes~\cite{CCS:CWPCR17,EuroSP:THS19}. One potential downside to this approach is that the cache might inadvertently contain credentials from other user accounts making cached data valuable to the attacker. More empirical study would be needed to determine the risks and benefits of maintaining such a cache. 


%To verify the performance of $\DALock$ over a reasonably long time span, we simulate the login activities over time span of 180 days, or 4320 hours.  Each random variable t, or login activity, is generated from range 0 to 4320 to represent u' login activities at time R over 180-day time span (rounded to hours). The smaller value of $t_u$, the more frequent u logins into her accounts. To have a realistic representation of login pattern, for each user u, $t_u$ is sampled uniformly random from \{ 12, 24, 24 * 3, 24 * 7, 24 * 14, 24 * 30\}.

%We assume that for each login activitiy, users will keep trying until they successfully login into their account, or get locked out unfortunately. Therefore, more than one acutal login attempts can be generated for each activitiy. We define each login attempt to be a 4 tuple (t, r, $\strikeThresholdofUAtT{u}{t}$,$\hitCountThresholdofUAtT{u}{t}$, ) $\in$ $(\mathsf{N}, \{\textit{success, fail} \}, \mathsf{N}, \mathsf{R}   \} )$   %$(t, r, \strikeCountThresholdofUAtT{u}{t}, \hitCountThresholdofUAtT{u}{t})$ %

%Notice that for each login activity, more than one login attempts can be generated because of users' mistakes. Naturally, we simulate each login activity by assuming that users will keep trying until they successfully login into their account or get locked out unfortunately.



\subsubsection{Simulating User Mistakes}\label{section:ExperimentDesign-subsection:SimulateUser-subsubsection:SimulateUserMistake} %Done
The last component of our user model is a mechanism to simulate user mistakes during the authentication process. Our model relies upon recent empirical studies of password typos~\cite{CCS:CWPCR17,SP:CAAJR16} and additionally incorporates other common user mistakes e.g., recall errors. The aforementioned studies show that roughly $7.5\%$ of login attempts are mistakes and at least $68\%$ of these mistakes are (most likely) typos i.e., within edit distance $2$ of the original passwords.  
Accordingly, we set the mistake rate to be $7.5\%$ for simulation. When simulating each login attempt the user will enter the correct password with probability $92.5\%$. Otherwise, if the user makes a mistake, we simulate a typo with probability $68\%$ and we simulate a recall error with probably $32\%$. To simulate a recall error we randomly select one of the user's five alternate passwords to model a user who forgot which of his passwords was associated with this particular account --- if the user recalls the wrong password they might additionally miss-type it (with probability $0.075\cdot 0.68$).  We refer an interested reader to the appendix for a more detailed discussion of our mistake model including a flow chart (see Figure~\ref{figure:flowChartTypo}) and more fine-grained typo statistics (see  Table~\ref{Table:TypoTypes}).

We remark that we do not attempt to simulate a user who completely forgets his password. Of course, we expect that this will occasionally happen in reality. However, we observe that a user who forgets his password will {\em always} need to reset it regardless of the throttling mechanism adopted by the authentication server. 

% that each user has selected an additional 5 passwords that might be confused with the original password --- 

% \jeremiah{May want to consider updating user model s.t. users have more than one additional password. To do add references to the specific appendix sections.}
%\wuwei{It's 5 passwords now}


%This is the last challenging ingredient for simulating user's login activities. In order to reasonably simulate user's mistakes, two major type mistakes were taking into considerations: entering a different password or making typos on the original passwords. We followed a recently published statics on usersâ€™ mistakes\cite{CCS:CWPCR17} to setup the probability of users' (varies type of) mistakes. Based on the results of the literatures, users have roughly 7.5\% chance of making a mistake (Pr(Mistake) = 0.075). Among those mistakes 68\% of those incorrect attempts are within editing distance 2. To simplify the model and analysis, we consider that as the probability as making typos. i.e. given a password p, user has probability $0.075\cdot 0.68$ of typing it wrong. We summarized the distribution of various types of typos in Table~\ref{Table:TypoTypes} for reader's convenience.  Furthermore, we consider the rest 32\% errors come from entering wrong passwords (editing distance greater than 2), in another word, entering different passwords. Therefore, each user has probability $0.075\cdot 0.32$ to select a wrong password to attempt (of course, the user can make typos on top of that!). We setup such secondary passwords (in users' mind) when users are created by randomly sampling a different password for each user based on the distribution of passwords. To help readers capture the essence of user's honest mistakes are simulated in our experiment, we present the flow chart in Figure ~\ref{fig:flowChartTypo}, \textbf{Appendix}.
