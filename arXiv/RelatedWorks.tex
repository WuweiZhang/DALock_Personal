% !TEX root = main.tex
% Differential Private Releasing
\section{Related Works and Backbrounds}\label{sec: relatedwork}

\subsection{Authentication Throttling} \label{related: Throttling}

\mypara{K-strike Mechanism} K-strike mechanism  is a straight-forward implementation for authentication throttling. As its name suggests, throttling occurs when $\strikeThreshold$ consecutive incorrect login attempts are detected.  To reduce the cost of expensive overhead caused by unwanted throttling, Brostoff et.al~\cite{brostoff2003ten}  suggest setting threshold $\strikeThreshold$ to be 10 instead of 3. They argue the increment risk is limited when strong password policy is enforced. However, this argument is challenged by empirical analyses of password composition policies~\cite{KSKMBCCE:SIGCHI11}\cite{BKPS:ACMEC13}. Many password composition policies do not rule out all low entropy password choices. For instance, it turns out that banning dictionary words does not increase entropy as expected.~\cite{KSKMBCCE:SIGCHI11} 

\mypara{Feature-Based Mechanism} To improve performance, modern throttling mechanisms\cite{sandhu2005system}\cite{gordon2014efficiently} often times use features such geographical location, IP-address, device information, and etc in addition to the correctness of attempting password. These features can be used to train sophisticated machine learning models to help distinguish between malicious and benign login attempts~\cite{NDSS:FJDBG16}. $\DALock$ takes an orthogonal approach and relies instead on the popularity of the password guesses. One can combine those models with a rigious throttling system for a better performance.

\mypara{Password-Distribution Aware Throttling} In an independent line of work Tian et al.~\cite{EuroSP:THS19} developed an IP-based throttling mechanism which exploits differences between the distribution of honest login attempts and attacker guesses. In particular, they propose to ``silently block'' login attempts from a particular IP address $a$ if the system detects too many popular passwords being submitted from that IP address. In more detail StopGuessing uses a data-structure called the binomial ladder filter~\cite{SchHer:MSR18} to (approximately) track the frequency $F(p)$ of each incorrect password guess. For each IP address the StopGuessing protocol maintains an associated counter $I_a = \displaystyle{\sum_{p \in \mathcal{P}} F(p)}$ where $\mathcal{P}$ is a list of incorrect password guesses that have been (recently) submitted from that IP address --- $I_a$ can be updated without storing $\mathcal{P}$ explicitly. Intuitively (and oversimplifying a bit) if $I_a > T$ then login attempts from address $a$ are silently blocked i.e., even if the attacker (or honest user) submits a correct password the system will respond that authentication fails. The authors also suggest protecting accounts with weak passwords by setting a user specific threshold $T(F(u_p))$ based on the strength $F(u_p)$ of the password $\PasswordOfU{u}$ of user $u$. Now if $I_a > T(F(u_p))$ then the system will silently reject any password from address $a$. Both StopGuessing and $\DALock$ exploit differences between the distribution of user passwords and attacker guesses. One of the key differences is that StopGuessing focuses on identifying malicious IP addresses (by maintaining a score $I_a$) while $\DALock$ focuses on protecting individual accounts by maintaining a ``hit-count'' parameter
$\hitCountThreshold{u}$ for each user u. There are several other key differences between the two approaches. First, in $\DALock$ the goal of our frequency oracle (e.g., count-sketch, password strength meter) is to estimate the total fraction of users who have actually selected that particular password --- as opposed to estimating the frequency with which that password has been {\em recently} submitted as a incorrect guess. Second, $\DALock$ does not require silent blocking of login attempts which could create usability concerns if an honest user is silently blocked when they enter the correct password.  

% StopGuessing\cite{EuroSP:THS19}, a concurrent work also uses the ``distribution of passwords", is an IP-based throttling mechanism. An IP address is banned if too many popular passwords were attempted. To identify whether a password $p$ has been frequently attempted, StopGuessing uses binomial ladder filter\cite{SchHer:MSR18} data structure to store the frequencies of \textit{incorrectly} guessed passwords and answer the query accordingly. Bionomial ladder filter returns an accurate frequency estimation $F(p)$ if $p$ is among one of those popular guesses. For each IP address, StopGuessing maintains a counter $I$ to keep track of the cumulative value of incorrectly attempted passwords $\mathcal{P} = \{p_1,\ldots,p_i\}$. i.e. $I = \displaystyle{\sum_{p \in \mathcal{P}} F(p)}$. Let $u_p$ be the password of user $u$, throttling is triggered when I exceeds $T(F(u_p))$ for some function T. Such threshold $T$ decreases as F($u_p$) increases. Both StopGuessing and $\DALock$ uses the distribution of passwords to perform throttling, the underlying mechanisms various in multiple aspects. Detailed comparisons can be found in \textbf{section}~\ref{sec: limitationAndDiscussion}

\subsection{Passwords} \label{related: Passwords}  
\mypara{Password Distribution} Password distribution naturally represents the chance of success in the setting of statistical guessing attacks. Password distribution has been extensively studied since last decades\cite{FloHer:WWW07}\cite{DavKev:WWW12}. Using leaked password corpora\cite{Dataset:RockYou}\cite{Dataset:LinkedIn}\cite{SP:Bonneau12} is a straight forward way to describe the distribution of passwords. In recent works of Wang et al.~\cite{EPRINT:WJHW14,TIFS17:WCWPXG,ESORICS:WanWan16} they argue that password distributions follow Zipf's law i.e., leaked password corpora nicely fit Zipf's law distributions. Blocki et al.~\cite{SP:BloHarZho18} later found that Zipf's law nicely fits the Yahoo! password frequency corpus~\cite{SP:Bonneau12,NDSS:BloDatBon16}. \\
\mypara{Password Typos}  To test the usability of $\DALock$, it's crucial to reasonably simulate users' mistakes. Recent studies\cite{CCS:CWPCR17,SP:CAAJR16} from Chatterjee et al. summarize probabilities of making (various of) typos when one enters his or her password based on users' studies. Based on the empirically measured data, they purposed two typo-tolerant authentication systems without sacrificing security. In fact, such mechanism has already been deployed in industry\cite{News:FacebookCaseSensitiveNews}\cite{News:AmazonTypo}. 

\subsection{Eliminating Dictionary Attacks} 

\mypara{Increasing Cost of Authentcation} Pinkas and Sanders~\cite{CCS:PinSan02} proposed the use of puzzles (e.g., proofs of work or CAPTCHAs) as a way to throttle online password crackers. CAPTCHAs are hard AI challenges meant to distinguish people from bots~\cite{EC:vBHL03}. For example, reCAPTCHA~\cite{von2008recaptcha} has been widely deployed in online web services such as Google, Facebook, Twitter, CNN, and etc. Assuming that CAPTCHAs are only solvable by people, one can mitigate automated online dictionary attacks without freezing users' accounts~\cite{SP:BBFNJ10,CCS:BurMarMit11}. However, an attacker can always pay humans to solve these CAPTCHA challenges\cite{captchaSolver}. Evolving CAPTCHA solvers~\cite{NDSS:GYCZLT16,CCS:YTFZFX18} powered by neural networks make it increasingly difficult to design CAPTCHA puzzles that are also easy for a human to solve.  Golla~et al.~\cite{SOUPS:GBD17} proposed a fee-based password verification system where a small deposit is necessary to authenticate, which is refunded after successful authentication. A password cracker risks loosing its deposit if it is not able to guess the real password.  


\mypara{Eliminating Popular Passwords} One mediation for dictionary attacks is eliminating the existence of weak or popular passwords. Schechter et al.~\cite{HTS:SchHerMit10} show that it is possible to forbid the existence of over popular password by maintaining the password distribution securely. Industrial solutions such as ``Have I been pwned?"~\cite{WebSite:HaveIBeenPwned} and ``Password CheckUp"~\cite{WebSite:GooglePasswordCheckUp} " prevent users to choose weak passwords based on data breaches. Password strength meters such as $\ZXCVBN$~\cite{USENIX:Wheeler16} are also been widely deployed to help users choosing stronger passwords.

%\mypara{Two Factor Authentication(2FA)} 2FA\cite{ICCSA:AFZSEW09} typically requires users to enter a short real time verification code along with their credentials. Without access to the message receiver adversaries are not able to login into users' accounts even if they enter the correct passwords. Recent studies 

\subsection{Privacy Perserving Aggregate Statistics Releasing.} \label{related: dp} $\DALock$ relies on the distribution of passwords to perform throttling. Storing/Releasing aggregate statistics naively often causes privacy leakage~\cite{arXiv:NarShm06}~\cite{UTA:NarShm08}. To answer the challenge, Cynthia Dwork purposed Differential Privacy~\cite{ECS:Dwork11} for aggregated data releasing. Informally speaking, differential private algorithm makes powerful adversaries unable of telling the existence of a record in the dataset. We defer the formal definition of differential privacy to section \ref{section:Prelinmaries-DiffernetialPrivacy}. Blocki et.al released the statics of Yahoo! dataset consist of 70 millions of passwords.~\cite{NDSS:BloDatBon16}. Recent work by Naor et al~\cite{CCS:NaoPinRon19} also demonstrates that releasing the distribution of password privately is feasible. In industry, Differential Privacy has been considered as the golden tool for various of tasks~\cite{AppleDP,AppleDPTeam,CCS:ErlPihKor14}.  

