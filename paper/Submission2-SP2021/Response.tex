\section{Comments and Improvements}

We previously submitted the paper to CCS 2020. We copied the full reviews below along with our rebuttal. Here we focus on summarizing the primary changes to the paper.

\mypara{Additional Datasets} Previously, our empirical analysis was based entirely on three password datasets: LinkedIn, RockYou, and Yahoo. Reviewer A strongly encouraged us to base the simulations on additional datasets. In this submission, we expanded our empirical analysis to include results from 5 additional password datasets: 000webhost, CSDN, clixsense, brazzers, and bfield. Now the datasets have more diversity than the previous version of our work. Firstly, small datasets such as bfield and brazzers are included in the experiments to test if $\DALock$ can still be effective when there is less data to train the differentially private count sketch used as a frequency oracle in $\DALock$. Secondly, the updated experimental results show that $\DALock$ is also effective on flatter distributions such as 000webhost and clixsense where users select stronger passwords.  

\mypara{Expanded Empirical Results Exploring the Impact of ban-list Size on $\DALock$} Both reviewers mentioned that they would like to see more details on how banning passwords affect $\DALock$. In an attempt to encourage users to pick stronger passwords, organizations can choose to ban overly popular passwords. In our last CCS submission, we simulated (1) an authentication server with no ban-list, and (2) an authentication server that bans the top $B=10^4$ passwords. There was little discussion about why we selected $B=10^4$. In this paper, we repeated our empirical analysis with a wide range of ban-list parameters $B\in\{0,5,10,100, 10^3,10^4, 10^5\}$ when comparing the performance of $\DALock$ with the traditional throttling mechanism. We also added discussion about the usability tradeoffs involved with selecting a larger ban-list, e.g., how many users are inconvenienced when they are forced to pick a different password during the registration. Our results show that banning too many passwords, e.g., $10^5$, can annoy up to 50\% of users during the password creation stage. Thus, we choose to present the results of banning passwords of size less than $10^5$. Even when $B=10^5$ passwords were banned, $\DALock$ still outperforms $k$-strike mechanism in the sense that fewer passwords are cracked, and fewer users get locked out--- see empirical results in Section V. 

%we only provide one data point (banning $10^4$ passwords) but we failed to clarify why such point is chosen. In this submission, we made the following improvements. First, we provide more data points: banning 0, 5, 10, $10^2$, $10^3$, $10^4$, and $10^5$ to demonstrate the effect on banning passwords on $\DALock$ and traditional throttling mechanism.  Second, we demonstrate how banning passwords can affect users in Section V, figure 3. 

%\mypara{Use More Datasets} Another common suggestion from CCS 2020 submission is repeating our experiments on more datasets. In previous submission we only include three large password datasets: LinkedIn, RockYou, and Yahoo. Therefore, in this submission we include 5 more leaked datasets: 000webhost, CSDN, clixsense, brazzers, and bfield. Now the datasets have more diversity than previous version of our work. Firstly, small datasets such as bfield and brazzers are included in the experiments to test if $\DALock$ can still be effective. Secondly, we are able to show the $\DALock$ can be effective on flatter distributions such as 000webhost and clixsense. 

\mypara{Improve Writing} Both reviewers identified a number of typos and grammatical errors which we have corrected. Both reviews contained a few significant misunderstandings about $\DALock$ which were likely due to poor organization. We reorganized portions of the paper to clarify some of these points. For example, in the introduction, we added a discussion of the password knapsack problem which we use to model the optimal behavior of an attacker who is familiar with the exact specification of the $\DALock$ mechanism. This addresses a concern of Reviewer B who mentioned, ``I was hoping for more depth in Sec. 5.4.1 (Optimizing Attack Strategies). Ultimately, if the attacker knows that common guesses will be highly penalized, wouldn't they adopt some strategy that mixes common guesses with uncommon guesses so that the k-strikes limit (not the DALock frequency-sensitive limit) is hit? As a result, the paper seems not to capture an actual attacker strategy." Similarly, we added a discussion about how an attacker could adapt if an organization bans the top 50 passwords. 

\mypara{Expanded Comparison with StopGuessing (Tian et al.)} Both reviewers noted that there are similarities between our work and StopGuessing. As context, we want to clarify that our work on DALock has been ongoing long before the StopGuessing paper was published or before we were even aware of that paper. As such, the DALock mechanism was developed independently of StopGuessing. We certainly agree that there are similar ideas behind StopGuessing and $\DALock$. However, we disagree that the differences are "mostly nuances." One can view the two papers as taking complementary/orthogonal approaches, i.e., StopGuessing primarily focuses on detecting IP addresses associated with malicious attackers and DALock focuses primarily on detecting attacks against specific accounts. In the updated paper, we have expanded our comparison with StopGuessing.  



% \mypara{Demonstrate the advantages of $\DALock$ more clearly} Reviewer A in last submission mentioned that dictionary attack can be easily solved by other approaches such as banning a few passwords based on some online literatures (e.g. a blog from Microsoft). We would like to make it clear that our experiments are designed to test the performance of throttling mechanism \textit{independently}, as other approaches can be used together with $\DALock$. Based on our results, security can be improved a lot when the ban-list is short, e.g., 50, if one uses $\DALock$. Third, we analysis of $\DALock$ under the attack of a powerful adversary, which is much more powerful than any realistic ones, and still able to show $\DALock$ provide superior security/usability trade-off. 

%\mypara{Our comments to previous review} We appreciate both reviewers gave lots of helpful and actionable suggestions; however, because the previous submission were poorly written, both reviewers were confused. 
%\begin{itemize}
%	\item Reviewer B mentioned ``I was hoping for more depth in Sec. 5.4.1 (Optimizing Attack Strategies). Ultimately, if the attacker knows that common guesses will be highly penalized, wouldn't they adopt some strategy that mixes common guesses with uncommon guesses so that the k-strikes limit (not the DALock frequency-sensitive limit) is hit? As a result, the paper seems not to capture an actual attacker strategy.".
	
%	We stress that we do model an attacker who adapts its guessing strategy in response to the DALock mechanism. We introduce the password knapsack problem (see Section 5.4) specifically to model an optimal adaptive attacker and view this as a key contribution of the work. Reviewer A argues that even a small ban list (e.g., top 50 passwords) would effectively mitigate the risk of an offline attack referencing a Microsoft blog. However, an adaptive attacker would simply move on to guess the most popular passwords that have not been banned. The attack would still be quite effective (e.g., passwords 51, 52, â€¦ are still quite popular)
	
%	\item Regarding the relationship to StopGuessing (Tian et al.): 
	

